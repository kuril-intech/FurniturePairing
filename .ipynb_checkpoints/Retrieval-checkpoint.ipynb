{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pymysql\n",
    "import io\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "from detection import generate_download_signed_url_v4\n",
    "from detection import get_similar_products_uri\n",
    "from detection import query_product\n",
    "\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "from google.cloud import storage\n",
    "from google.cloud import vision\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from PIL import Image\n",
    "from typing import Dict, Text\n",
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup Connection to mysql database\n",
    "conn = pymysql.connect(\n",
    "    host='35.221.181.94',\n",
    "    port=int(3306),\n",
    "    user=\"mkhoa\",\n",
    "    passwd='NTMK261194@dng',\n",
    "    db=\"project\",\n",
    "    charset='utf8mb4')\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "def query_item2room():\n",
    "    '''\n",
    "    Make dataframe for ImageDataGenerator\n",
    "    \n",
    "    '''\n",
    "    query = f'''\n",
    "    SELECT GROUP_CONCAT(room SEPARATOR ', ') as room, room_path\n",
    "    FROM project.item2room a\n",
    "    LEFT JOIN project.Files b ON a.item = b.id\n",
    "    WHERE b.bucket_path like '%Products%'\n",
    "    GROUP BY room_path \n",
    "    '''\n",
    "    try:\n",
    "        cur.execute(query)\n",
    "    except Exception as err:\n",
    "        print('ERROR BY SELECT:', err)\n",
    "    result = cur.fetchall()\n",
    "    result = pd.DataFrame(result, columns=['RoomID', 'RoomPath'])\n",
    "    return result\n",
    "\n",
    "def query_classes():\n",
    "    '''\n",
    "    Query for list of distinct room\n",
    "    \n",
    "    '''\n",
    "    query = f'''\n",
    "    SELECT distinct room\n",
    "    FROM project.item2room\n",
    "    '''\n",
    "    try:\n",
    "        cur.execute(query)\n",
    "    except Exception as err:\n",
    "        print('ERROR BY SELECT:', err)\n",
    "    result = cur.fetchall()\n",
    "    result = pd.DataFrame(result, columns=['RoomID'])\n",
    "    return result\n",
    "\n",
    "def query_item2item():\n",
    "    '''\n",
    "    Make dataframe for Item2Item Matching\n",
    "    \n",
    "    '''\n",
    "    query = f'''\n",
    "    WITH cte as(\n",
    "    SELECT id, url, bucket, bucket_path, obj_count\n",
    "    FROM project.Files\n",
    "    WHERE bucket_path not like \"%Design%\" AND bucket_path not like \"%Thumbnail%\")\n",
    "    SELECT \n",
    "    a.item as item1, \n",
    "    c.bucket_path as bucket1, \n",
    "    b.item as item2, \n",
    "    d.bucket_path as bucket2\n",
    "    FROM project.item2room a\n",
    "    INNER JOIN project.item2room b ON a.room = b.room\n",
    "    INNER JOIN cte c ON a.item = c.id\n",
    "    INNER JOIN cte d ON b.item = d.id\n",
    "    WHERE a.item != b.item\n",
    "    '''\n",
    "    try:\n",
    "        cur.execute(query)\n",
    "    except Exception as err:\n",
    "        print('ERROR BY SELECT:', err)\n",
    "    result = cur.fetchall()\n",
    "    result = pd.DataFrame(result, columns=['item1', 'bucket_path1', 'item2', 'bucket_path2' ])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucket2product(bucket_path):\n",
    "    '''\n",
    "    Reverse thumbnail bucket path to query product information\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    query = f'''\n",
    "    SELECT a.id, a.product, a.url\n",
    "    FROM project.ProductHeader a\n",
    "    LEFT JOIN project.Files b ON a.id = b.id\n",
    "    WHERE b.bucket_path = {{bucket_path}}\n",
    "    '''\n",
    "    try:\n",
    "        cur.execute(query)\n",
    "    except Exception as err:\n",
    "        print('ERROR BY SELECT:', err)\n",
    "    result = cur.fetchone()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "item2item = query_item2item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'abstract-veld-289612'\n",
    "bucket_name = 'ftmle'\n",
    "storage_client = storage.Client.from_service_account_json(\"./Credentials/abstract-veld-289612-327ddac80eba.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item1</th>\n",
       "      <th>bucket_path1</th>\n",
       "      <th>item2</th>\n",
       "      <th>bucket_path2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>204369</td>\n",
       "      <td>Images/Products/204369-0-601.963.58.jpg</td>\n",
       "      <td>202349</td>\n",
       "      <td>Images/Products/202349-0-802.017.40.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>203035</td>\n",
       "      <td>Images/Products/203035-0-902.142.85.jpg</td>\n",
       "      <td>202424</td>\n",
       "      <td>Images/Products/202424-0-198.850.43.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202508</td>\n",
       "      <td>Images/Products/202508-0-399.030.41.jpg</td>\n",
       "      <td>202507</td>\n",
       "      <td>Images/Products/202507-0-303.270.68.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202507</td>\n",
       "      <td>Images/Products/202507-0-303.270.68.jpg</td>\n",
       "      <td>202508</td>\n",
       "      <td>Images/Products/202508-0-399.030.41.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>203268</td>\n",
       "      <td>Images/Products/203268-0-602.178.22.jpg</td>\n",
       "      <td>202803</td>\n",
       "      <td>Images/Products/202803-0-802.418.16.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>204277</td>\n",
       "      <td>Images/Products/204277-0-302.580.41.jpg</td>\n",
       "      <td>204342</td>\n",
       "      <td>Images/Products/204342-0-202.085.27.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>202349</td>\n",
       "      <td>Images/Products/202349-0-802.017.40.jpg</td>\n",
       "      <td>204369</td>\n",
       "      <td>Images/Products/204369-0-601.963.58.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>204320</td>\n",
       "      <td>Images/Products/204320-0-668.040.47.jpg</td>\n",
       "      <td>204384</td>\n",
       "      <td>Images/Products/204384-0-902.874.13.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>204299</td>\n",
       "      <td>Images/Products/204299-0-103.064.39.jpg</td>\n",
       "      <td>204384</td>\n",
       "      <td>Images/Products/204384-0-902.874.13.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>204277</td>\n",
       "      <td>Images/Products/204277-0-302.580.41.jpg</td>\n",
       "      <td>204384</td>\n",
       "      <td>Images/Products/204384-0-902.874.13.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      item1                             bucket_path1   item2  \\\n",
       "0    204369  Images/Products/204369-0-601.963.58.jpg  202349   \n",
       "1    203035  Images/Products/203035-0-902.142.85.jpg  202424   \n",
       "2    202508  Images/Products/202508-0-399.030.41.jpg  202507   \n",
       "3    202507  Images/Products/202507-0-303.270.68.jpg  202508   \n",
       "4    203268  Images/Products/203268-0-602.178.22.jpg  202803   \n",
       "..      ...                                      ...     ...   \n",
       "147  204277  Images/Products/204277-0-302.580.41.jpg  204342   \n",
       "148  202349  Images/Products/202349-0-802.017.40.jpg  204369   \n",
       "149  204320  Images/Products/204320-0-668.040.47.jpg  204384   \n",
       "150  204299  Images/Products/204299-0-103.064.39.jpg  204384   \n",
       "151  204277  Images/Products/204277-0-302.580.41.jpg  204384   \n",
       "\n",
       "                                bucket_path2  \n",
       "0    Images/Products/202349-0-802.017.40.jpg  \n",
       "1    Images/Products/202424-0-198.850.43.jpg  \n",
       "2    Images/Products/202507-0-303.270.68.jpg  \n",
       "3    Images/Products/202508-0-399.030.41.jpg  \n",
       "4    Images/Products/202803-0-802.418.16.jpg  \n",
       "..                                       ...  \n",
       "147  Images/Products/204342-0-202.085.27.jpg  \n",
       "148  Images/Products/204369-0-601.963.58.jpg  \n",
       "149  Images/Products/204384-0-902.874.13.jpg  \n",
       "150  Images/Products/204384-0-902.874.13.jpg  \n",
       "151  Images/Products/204384-0-902.874.13.jpg  \n",
       "\n",
       "[152 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item2item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bucket_image(path):\n",
    "    '''\n",
    "    Load GCS iamge from bucket\n",
    "    \n",
    "    '''\n",
    "    path = str(path.numpy().decode(\"utf-8\"))\n",
    "    blob = storage_client.bucket(bucket_name).get_blob(path)\n",
    "    img = blob.download_as_string()\n",
    "\n",
    "    return img\n",
    "\n",
    "def preprocess_image(bucket_path):\n",
    "    '''\n",
    "    Preprocess image from bucket path\n",
    "    \n",
    "    '''\n",
    "    img = tf.py_function(load_bucket_image, [bucket_path], tf.string)\n",
    "    img = tf.image.decode_image(img, channels=3, expand_animations = False)\n",
    "    img = tf.image.resize(img, (244, 244))\n",
    "    img = img/255\n",
    "    img = tf.cast(img, tf.float32)\n",
    "\n",
    "    return img\n",
    "\n",
    "# The tuples are unpacked into the positional arguments of the mapped function\n",
    "def load_and_preprocess_from_path_label(path1, path2):\n",
    "  return {\"item1\": preprocess_image(path1), \"item2\": preprocess_image(path2)}\n",
    "\n",
    "# The tuples are unpacked into the positional arguments of the mapped function\n",
    "def load_and_preprocess_candidate(path):\n",
    "  return preprocess_image(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate = tf.data.Dataset.from_tensor_slices((item2item['bucket_path2']))\n",
    "candidate_map = candidate.map(load_and_preprocess_candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(item2item, test_size=0.1)\n",
    "train = tf.data.Dataset.from_tensor_slices((df_train['bucket_path1'], df_train['bucket_path2']))\n",
    "train_map = train.map(load_and_preprocess_from_path_label)\n",
    "test = tf.data.Dataset.from_tensor_slices((df_test['bucket_path1'],df_test['bucket_path2']))\n",
    "test_map = test.map(load_and_preprocess_from_path_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter\n",
    "BATCH_SIZE = 1\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_set = train_map.batch(BATCH_SIZE)\n",
    "test_set = test_map.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_set = candidate_map.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairModel(tfrs.Model):\n",
    "\n",
    "  def __init__(self, tower1_model, tower2_model):\n",
    "    super().__init__()\n",
    "    self.tower1_model: tf.keras.Model = tower1_model #movie_model\n",
    "    self.tower2_model: tf.keras.Model = tower2_model #user_model\n",
    "    self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    # We pick out the user features and pass them into the user model.\n",
    "    tower1_embeddings = self.tower1_model(features[\"item1\"])\n",
    "    # And pick out the movie features and pass them into the movie model,\n",
    "    # getting embeddings back.\n",
    "    positive_tower2_embeddings = self.tower2_model(features[\"item2\"])\n",
    "\n",
    "    # The task computes the loss and the metrics.\n",
    "    return self.task(tower1_embeddings, positive_tower2_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tower1_model = InceptionV3(include_top=False, input_shape=(244, 244, 3))\n",
    "for layer in tower1_model.layers:\n",
    "    layer.trainable = False\n",
    "flat1 = Flatten()(tower1_model.layers[-1].output)\n",
    "class1 = Dense(244, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "# define new model\n",
    "tower1_model = Model(inputs=tower1_model.inputs, outputs=class1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tower2_model = InceptionV3(include_top=False, input_shape=(244, 244, 3))\n",
    "for layer in tower2_model.layers:\n",
    "    layer.trainable = False\n",
    "flat1 = Flatten()(tower2_model.layers[-1].output)\n",
    "class1 = Dense(244, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "# define new model\n",
    "tower2_model = Model(inputs=[tower2_model.inputs], outputs=[class1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "  candidates=candidate_set.map(tower2_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = tfrs.tasks.Retrieval(\n",
    "  metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PairModel(tower1_model, tower2_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:XLA_GPU:0'):\n",
    "    model.fit(train_set, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = tfrs.layers.ann.BruteForce(model.tower2_model)\n",
    "index.index(candidate_set.map(model.tower1_model), candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = load_and_preprocess_candidate('Images/Products/204369-0-601.963.58.jpg')\n",
    "x = tf.expand_dims(x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for Furniture: [b'Images/Products/204064-0-802.671.37.jpg'\n",
      " b'Images/Products/204064-0-802.671.37.jpg'\n",
      " b'Images/Products/204064-0-802.671.37.jpg'\n",
      " b'Images/Products/204064-0-802.671.37.jpg'\n",
      " b'Images/Products/204064-0-802.671.37.jpg'\n",
      " b'Images/Products/203268-0-602.178.22.jpg'\n",
      " b'Images/Products/202349-0-802.017.40.jpg'\n",
      " b'Images/Products/202424-0-198.850.43.jpg'\n",
      " b'Images/Products/202507-0-303.270.68.jpg'\n",
      " b'Images/Products/202508-0-399.030.41.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Get recommendations.\n",
    "_, titles = index(x)\n",
    "print(f\"Recommendations for Furniture: {titles[0, :10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.tower1_model.save('Retrieval_tower1.h5')\n",
    "model.tower2_model.save('Retrieval_tower2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "tower1_model = tf.keras.models.load_model('./Model/Retrieval_tower1.h5')\n",
    "tower2_model = tf.keras.models.load_model('./Model/Retrieval_tower2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - factorized_top_k: 0.2375 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0625 - factorized_top_k/top_10_categorical_accuracy: 0.0625 - factorized_top_k/top_50_categorical_accuracy: 0.3750 - factorized_top_k/top_100_categorical_accuracy: 0.6875 - loss: 97.4308 - regularization_loss: 0.0000e+00 - total_loss: 97.4308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k': array([0.    , 0.0625, 0.0625, 0.375 , 0.6875], dtype=float32),\n",
       " 'factorized_top_k/top_1_categorical_accuracy': 0.0,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.0625,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.0625,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.375,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.6875,\n",
       " 'loss': 97.43084716796875,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 97.43084716796875}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = AnnoyIndex(244, \"dot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_embeddings = candidate.enumerate().map(lambda idx, bucket_path2: (idx, bucket_path2, model.tower2_model(tf.expand_dims(load_and_preprocess_candidate(bucket_path2), axis=0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_to_path = dict((idx, title) for idx, title, _ in candidate_embeddings.as_numpy_iterator())\n",
    "pickle.dump(candidate_to_path, open(\"'./Model/candidate_to_path.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-05504958558e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Model/candidate_to_path.p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mcandidate_to_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "with open('./Model/candidate_to_path.p', 'rb') as handle:\n",
    "    candidate_to_path = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'candidate_to_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-08626e5b34e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcandidate_to_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'candidate_to_path' is not defined"
     ]
    }
   ],
   "source": [
    "candidate_to_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We unbatch the dataset because Annoy accepts only scalar (id, embedding) pairs.\n",
    "for candidate_id, _, embedding in candidate_embeddings.as_numpy_iterator():\n",
    "  index.add_item(candidate_id, embedding[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.build(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.save('index.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = AnnoyIndex(244, \"dot\")\n",
    "index.load('index.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidates: ['Images/Products/203750-0-202.016.82.jpg', 'Images/Products/203750-0-202.016.82.jpg', 'Images/Products/203046-0-702.068.04.jpg', 'Images/Products/203171-0-502.345.82.jpg', 'Images/Products/203171-0-502.345.82.jpg', 'Images/Products/203649-0-790.462.60.jpg', 'Images/Products/202424-0-198.850.43.jpg', 'Images/Products/203293-0-402.808.43.jpg', 'Images/Products/203293-0-402.808.43.jpg', 'Images/Products/203408-0-702.535.41.jpg'].\n"
     ]
    }
   ],
   "source": [
    "x = load_and_preprocess_candidate('Images/Products/204369-0-601.963.58.jpg')\n",
    "x = tf.expand_dims(x, axis=0)\n",
    "query_embedding = model.tower1_model(x)\n",
    "candidates = index.get_nns_by_vector(query_embedding[0], 10)\n",
    "print(f\"Candidates: {[candidate_to_path[x].decode('utf-8') for x in candidates]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item1</th>\n",
       "      <th>bucket_path1</th>\n",
       "      <th>item2</th>\n",
       "      <th>bucket_path2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>204369</td>\n",
       "      <td>Images/Products/204369-0-601.963.58.jpg</td>\n",
       "      <td>202349</td>\n",
       "      <td>Images/Products/202349-0-802.017.40.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    item1                             bucket_path1   item2  \\\n",
       "0  204369  Images/Products/204369-0-601.963.58.jpg  202349   \n",
       "\n",
       "                              bucket_path2  \n",
       "0  Images/Products/202349-0-802.017.40.jpg  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item2item[item2item['bucket_path1'] == 'Images/Products/204369-0-601.963.58.jpg']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
